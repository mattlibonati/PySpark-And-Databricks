{"cells":[{"cell_type":"markdown","source":["### Overview"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3de8dae5-ca63-4dc4-b3f4-4e1838164eab","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["DataFrames are common Spark data objects. This script covers methods for creating DataFrames, specifying input, and explicitly declaring column names and formats."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3ffa12bc-94ec-4de2-a68e-66d95888b10f","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Creating Spark DataFrames"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1f3dd741-95bc-4191-8b24-3b166634964b","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["##### Explicity State Data and Columns:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6ac1b50d-7640-49e2-afe3-76d9f37223b5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Example 1: Explicitly state data and column params\nsdf = spark.createDataFrame(\n  data = [\n    (1001,'Chicago',535),          ##  \n    (1002,'Boston',495),            # #Values\n    (1003,'Seattle',318),          ##\n  ],\n  schema = ['station_id','city','rainfall']  # column names \n)\n\ndisplay(sdf)\n\n# Example 2: Ignore explicit data and column params\nsdf = spark.createDataFrame(\n  [                                # <-- this line no longer has a \"data = \"\n    (1001,'Chicago',535),          \n    (1002,'Boston',495) ,          \n    (1003,'Seattle',318),          \n  ],\n  ['station_id','city','rainfall'] # <-- this line no longer has a \"schema = \"\n)\n\ndisplay(sdf)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aa07f80b-c477-4e1c-bae2-d40c2c1686d1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[1001,"Chicago",535],[1002,"Boston",495],[1003,"Seattle",318]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"station_id","type":"\"long\"","metadata":"{}"},{"name":"city","type":"\"string\"","metadata":"{}"},{"name":"rainfall","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>station_id</th><th>city</th><th>rainfall</th></tr></thead><tbody><tr><td>1001</td><td>Chicago</td><td>535</td></tr><tr><td>1002</td><td>Boston</td><td>495</td></tr><tr><td>1003</td><td>Seattle</td><td>318</td></tr></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[1001,"Chicago",535],[1002,"Boston",495],[1003,"Seattle",318]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"station_id","type":"\"long\"","metadata":"{}"},{"name":"city","type":"\"string\"","metadata":"{}"},{"name":"rainfall","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>station_id</th><th>city</th><th>rainfall</th></tr></thead><tbody><tr><td>1001</td><td>Chicago</td><td>535</td></tr><tr><td>1002</td><td>Boston</td><td>495</td></tr><tr><td>1003</td><td>Seattle</td><td>318</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### Implicitly State Data and Columns Using Lists:\nAlternatively, you can input lists into the createDataFrame() function..."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"89ef1e91-d89b-4c78-b69b-b17c8eed8739","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Example 1: Implicitly state data and column params\ndata = [\n    (1001,'Chicago',535),            \n    (1002,'Boston',495),           \n    (1003,'Seattle',318),          \n]\n\ncolumns = ['station_id','city','rainfall']\n\nsdf = spark.createDataFrame(data=data, schema=columns) # <-- the data and column objects referenced here \n\ndisplay(sdf)\n\n# Example 2: Ignore implicit data and column params\ndata = [\n    (1001,'Chicago',535),            \n    (1002,'Boston',495),           \n    (1003,'Seattle',318),          \n]\n\ncolumns = ['station_id','city','rainfall']\n\nsdf = spark.createDataFrame(data, columns)             # <-- \"data =\" & \"schema =\" no longer stated\n\ndisplay(sdf)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e004be7b-54d8-4a33-8ff6-d2e55be869cf","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Creating a Spark DataFrame with Explicity Stated Formatting\nThe pyspark.sql.types module provides functions which will allow you to define each columns data types when creating as Spark DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ab36d93d-f52b-4a39-9d06-d586c29fd81f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.types import * # <-- this will import all of the different datatypes \n\ndata = [\n    (1001,'Chicago',535 , None),    ##  \n    (1002,'Boston' ,495 , None),     # Values\n    (1003,'Seattle',318 , None),     #\n    (None,None     ,None, None),    ##\n]\n\nschema = StructType([\n   StructField(\"station_id\", IntegerType(), True),   ##\n   StructField(\"city\"      , StringType() , True),    # Column Names & Formats \n   StructField(\"rainfall\"  , IntegerType(), True),    # IntegerType()/ StringType() are 2 of the imported datatypes\n   StructField(\"comments\"  , StringType() , True)])  ##\n\nsdf = spark.createDataFrame(data, schema)\n\ndisplay(sdf)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7d233ba9-9994-4022-899c-6622a3dd9030","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[1001,"Chicago",535,null],[1002,"Boston",495,null],[1003,"Seattle",318,null],[null,null,null,null]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"station_id","type":"\"integer\"","metadata":"{}"},{"name":"city","type":"\"string\"","metadata":"{}"},{"name":"rainfall","type":"\"integer\"","metadata":"{}"},{"name":"comments","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>station_id</th><th>city</th><th>rainfall</th><th>comments</th></tr></thead><tbody><tr><td>1001</td><td>Chicago</td><td>535</td><td>null</td></tr><tr><td>1002</td><td>Boston</td><td>495</td><td>null</td></tr><tr><td>1003</td><td>Seattle</td><td>318</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Viewing Data with the display() and show() Functions:  \nThe display() function is only 1 way to view data withina Spark DataFrame. The show() provides some additional flexibily such as truncating text, and transposing the view."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4a7642f8-463c-4669-ad78-791a924ea8db","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# the display function can be used two ways\nsdf.display()\n# or \ndisplay(sdf)\n\n##################################################\n# Method 2: show() function\n# \n\nsdf.show(n        = 2    ,  # number of rows \n         truncate = 3)      # Uses truncate = 3 to limit cell output to 3 characters in length; 20 characters by default\n\n# Uses truncate = False to eliminate cell truncation\nsdf.show(n        = 2    ,  \n         truncate = False)  \n\n# Uses vertical = True to display the data vertically\nsdf.show(vertical  = True)  "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b145c55a-b0e1-4c9a-a5ca-1622feaa6d31","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[1001,"Chicago",535,null],[1002,"Boston",495,null],[1003,"Seattle",318,null],[null,null,null,null]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"station_id","type":"\"integer\"","metadata":"{}"},{"name":"city","type":"\"string\"","metadata":"{}"},{"name":"rainfall","type":"\"integer\"","metadata":"{}"},{"name":"comments","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>station_id</th><th>city</th><th>rainfall</th><th>comments</th></tr></thead><tbody><tr><td>1001</td><td>Chicago</td><td>535</td><td>null</td></tr><tr><td>1002</td><td>Boston</td><td>495</td><td>null</td></tr><tr><td>1003</td><td>Seattle</td><td>318</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[1001,"Chicago",535,null],[1002,"Boston",495,null],[1003,"Seattle",318,null],[null,null,null,null]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"station_id","type":"\"integer\"","metadata":"{}"},{"name":"city","type":"\"string\"","metadata":"{}"},{"name":"rainfall","type":"\"integer\"","metadata":"{}"},{"name":"comments","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>station_id</th><th>city</th><th>rainfall</th><th>comments</th></tr></thead><tbody><tr><td>1001</td><td>Chicago</td><td>535</td><td>null</td></tr><tr><td>1002</td><td>Boston</td><td>495</td><td>null</td></tr><tr><td>1003</td><td>Seattle</td><td>318</td><td>null</td></tr><tr><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+----+--------+--------+\n|station_id|city|rainfall|comments|\n+----------+----+--------+--------+\n|       100| Chi|     535|     nul|\n|       100| Bos|     495|     nul|\n+----------+----+--------+--------+\nonly showing top 2 rows\n\n+----------+-------+--------+--------+\n|station_id|city   |rainfall|comments|\n+----------+-------+--------+--------+\n|1001      |Chicago|535     |null    |\n|1002      |Boston |495     |null    |\n+----------+-------+--------+--------+\nonly showing top 2 rows\n\n-RECORD 0-------------\n station_id | 1001    \n city       | Chicago \n rainfall   | 535     \n comments   | null    \n-RECORD 1-------------\n station_id | 1002    \n city       | Boston  \n rainfall   | 495     \n comments   | null    \n-RECORD 2-------------\n station_id | 1003    \n city       | Seattle \n rainfall   | 318     \n comments   | null    \n-RECORD 3-------------\n station_id | null    \n city       | null    \n rainfall   | null    \n comments   | null    \n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+----+--------+--------+\n|station_id|city|rainfall|comments|\n+----------+----+--------+--------+\n|       100| Chi|     535|     nul|\n|       100| Bos|     495|     nul|\n+----------+----+--------+--------+\nonly showing top 2 rows\n\n+----------+-------+--------+--------+\n|station_id|city   |rainfall|comments|\n+----------+-------+--------+--------+\n|1001      |Chicago|535     |null    |\n|1002      |Boston |495     |null    |\n+----------+-------+--------+--------+\nonly showing top 2 rows\n\n-RECORD 0-------------\n station_id | 1001    \n city       | Chicago \n rainfall   | 535     \n comments   | null    \n-RECORD 1-------------\n station_id | 1002    \n city       | Boston  \n rainfall   | 495     \n comments   | null    \n-RECORD 2-------------\n station_id | 1003    \n city       | Seattle \n rainfall   | 318     \n comments   | null    \n-RECORD 3-------------\n station_id | null    \n city       | null    \n rainfall   | null    \n comments   | null    \n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Some Additional Tips and Tricks:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"eeb5dfc9-1ea6-44b5-bd21-698bcf01de69","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["The \".columns\" command will return a list of column names..."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9f76c791-c7c9-4a5d-bc1f-651449f6be77","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["sdf.columns # obtain list of column names"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"034d5fc9-b0a3-469f-8857-3fdac2e7cd32","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[5]: ['station_id', 'city', 'rainfall', 'comments']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[5]: ['station_id', 'city', 'rainfall', 'comments']"]}}],"execution_count":0},{"cell_type":"markdown","source":["PySpark allows programmers to chain functions onto multiple lines via a backslash \" \\ \" :"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"453118b4-7cdb-4357-9e8d-29d86e0c8a11","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["sdf \\\n  .show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"48fc9712-16bc-482e-b4e0-cdc21798e76e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+-------+--------+--------+\n|station_id|city   |rainfall|comments|\n+----------+-------+--------+--------+\n|1001      |Chicago|535     |null    |\n|1002      |Boston |495     |null    |\n|1003      |Seattle|318     |null    |\n|null      |null   |null    |null    |\n+----------+-------+--------+--------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+-------+--------+--------+\n|station_id|city   |rainfall|comments|\n+----------+-------+--------+--------+\n|1001      |Chicago|535     |null    |\n|1002      |Boston |495     |null    |\n|1003      |Seattle|318     |null    |\n|null      |null   |null    |null    |\n+----------+-------+--------+--------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["No explicit \"shape\" command exists for Spark similar to Pandas as of the time of this writing. However, the shape of a Spark DataFrame can be obtained via workaround:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"de8c1341-f6d5-472d-9ac0-17a96c21c80a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def sdf_shape(sdf):\n    print(sdf.count(),len(sdf.columns))\n    \nsdf_shape(sdf)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"664c411a-cdb6-4e40-a890-4b2210b80a67","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"4 4\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["4 4\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"2. DataFrames","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3343101419846495}},"nbformat":4,"nbformat_minor":0}
