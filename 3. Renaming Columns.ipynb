{"cells":[{"cell_type":"markdown","source":["### Overview"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ccea1ab7-29c1-4b8f-a30d-99eb14966407","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Often times when working with data you will need to rename fields. For example, if you are engineering data for modelers to recalibrate an existing model, some of the column names will need to be renamed so that they fit into the modeler's script."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7ecc690d-9cb9-4670-a2b0-8eb375408b4e","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Start with creating a dataframe..."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"447928be-dbbb-4d25-8189-c75f92271da8","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["sdf = spark.createDataFrame(data=[(1001,'Chicago',535),          ##  \n                                  (1002,'Boston',495),            # #Values\n                                  (1003,'Seattle',318),          ##\n                                  ], \n                            schema=['station_id','city','rainfall']\n  ) \n\n\n# Print top 5 rows\nprint(sdf.show(n=5, truncate = False))\n\n# Print Schema \nprint(sdf.printSchema())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e7d461be-75ff-4c00-8353-f94776abc717","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"+----------+-------+--------+\n|station_id|city   |rainfall|\n+----------+-------+--------+\n|1001      |Chicago|535     |\n|1002      |Boston |495     |\n|1003      |Seattle|318     |\n+----------+-------+--------+\n\nNone\nroot\n |-- station_id: long (nullable = true)\n |-- city: string (nullable = true)\n |-- rainfall: long (nullable = true)\n\nNone\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----------+-------+--------+\n|station_id|city   |rainfall|\n+----------+-------+--------+\n|1001      |Chicago|535     |\n|1002      |Boston |495     |\n|1003      |Seattle|318     |\n+----------+-------+--------+\n\nNone\nroot\n |-- station_id: long (nullable = true)\n |-- city: string (nullable = true)\n |-- rainfall: long (nullable = true)\n\nNone\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Renaming Columns"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"130fd7da-fb5e-483e-9b13-f9823afa8298","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["#### .withColumnRenamed() function"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0dc82f71-1fdf-4144-8bb9-08617081c8b0","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["This will rename the column within a Spark DataFrame without droping any data elements."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"12e94631-790b-4d8c-a46b-406dffbfaede","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["sdf_renamed_columns = sdf.withColumnRenamed('city','city_US')\nprint('Renamed Column:')\nsdf_renamed_columns.show()\nprint('Original Column:')\nsdf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e65e9b09-2193-4d29-a341-90cfa67f4fc2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Renamed Column:\n+----------+-------+--------+\n|station_id|city_US|rainfall|\n+----------+-------+--------+\n|      1001|Chicago|     535|\n|      1002| Boston|     495|\n|      1003|Seattle|     318|\n+----------+-------+--------+\n\nOriginal Column:\n+----------+-------+--------+\n|station_id|   city|rainfall|\n+----------+-------+--------+\n|      1001|Chicago|     535|\n|      1002| Boston|     495|\n|      1003|Seattle|     318|\n+----------+-------+--------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Renamed Column:\n+----------+-------+--------+\n|station_id|city_US|rainfall|\n+----------+-------+--------+\n|      1001|Chicago|     535|\n|      1002| Boston|     495|\n|      1003|Seattle|     318|\n+----------+-------+--------+\n\nOriginal Column:\n+----------+-------+--------+\n|station_id|   city|rainfall|\n+----------+-------+--------+\n|      1001|Chicago|     535|\n|      1002| Boston|     495|\n|      1003|Seattle|     318|\n+----------+-------+--------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### .selectExpr() function:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ccec45d4-4802-4ade-ae80-ca293b07ebff","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["This function will only retain columns explicity stated within the function."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"29ce024e-239c-4dcb-aa4f-fec7a6826f8f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["sdf_selectExpr = sdf.selectExpr(\"city as city_US\")\nprint('Renamed Column:')\nsdf_selectExpr.show()\nprint('Original Column:')\nsdf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cd17935a-8803-4b00-a756-2d532a775d3b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Renamed Column:\n+-------+\n|city_US|\n+-------+\n|Chicago|\n| Boston|\n|Seattle|\n+-------+\n\nOriginal Column:\n+----------+-------+--------+\n|station_id|   city|rainfall|\n+----------+-------+--------+\n|      1001|Chicago|     535|\n|      1002| Boston|     495|\n|      1003|Seattle|     318|\n+----------+-------+--------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Renamed Column:\n+-------+\n|city_US|\n+-------+\n|Chicago|\n| Boston|\n|Seattle|\n+-------+\n\nOriginal Column:\n+----------+-------+--------+\n|station_id|   city|rainfall|\n+----------+-------+--------+\n|      1001|Chicago|     535|\n|      1002| Boston|     495|\n|      1003|Seattle|     318|\n+----------+-------+--------+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### .select() + .alias() functions:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"260e381d-b6eb-4468-9df5-b06aa0d3da06","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["This function will only retain columns explicity stated within the function. The combination of these two functions requires wrapping the original column's alias \"city\" with the col() function. This method is situational. For example, if you need a subset of columns from a big dataset to train a model, you could use the .select() + .alias() functions to grab all columns and rename based on model specs within a single command."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d3da16bb-7e33-4a39-9cc8-5764fac49e81","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pyspark.sql.functions as f\n\nsdf_selectAlias = sdf.select(f.col(\"city\").alias('city_US'))\nprint('Renamed Column:')\nsdf_selectExpr.show()\nprint('Original Column:')\nsdf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"057c0a1a-c475-4722-bc37-a9daa73c2c4a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Renamed Column:\n+-------+\n|city_US|\n+-------+\n|Chicago|\n| Boston|\n|Seattle|\n+-------+\n\nOriginal Column:\n+----------+-------+--------+\n|station_id|   city|rainfall|\n+----------+-------+--------+\n|      1001|Chicago|     535|\n|      1002| Boston|     495|\n|      1003|Seattle|     318|\n+----------+-------+--------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Renamed Column:\n+-------+\n|city_US|\n+-------+\n|Chicago|\n| Boston|\n|Seattle|\n+-------+\n\nOriginal Column:\n+----------+-------+--------+\n|station_id|   city|rainfall|\n+----------+-------+--------+\n|      1001|Chicago|     535|\n|      1002| Boston|     495|\n|      1003|Seattle|     318|\n+----------+-------+--------+\n\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"3. Renaming Columns","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4001415945662393}},"nbformat":4,"nbformat_minor":0}
